{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7acb2ba0-8fab-4811-a1f6-a96c77ad1cd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import libraries for data handling, ML model training, and evaluation.\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score, classification_report\n",
    "import lightgbm as lgb\n",
    "from lightgbm import early_stopping, log_evaluation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c13cff1f-3a28-415e-b46e-b61f35459fc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Generate a synthetic dataset simulating PE file features for machine learning to distinguish malware from benign software.\n",
    "n_samples = 5000      \n",
    "n_byte_features = 256 \n",
    "n_sections = 5        \n",
    "\n",
    "#creates synthetic PE sections for experiments without needing real PE files\n",
    "def random_sections(n):\n",
    "    sections = []\n",
    "    for _ in range(n):\n",
    "        sections.append({\n",
    "            'Entropy': np.random.rand(),\n",
    "            'VirtualSize': np.random.randint(1000, 100000),\n",
    "            'RawSize': np.random.randint(1000, 100000)\n",
    "        })\n",
    "    return sections\n",
    "    \n",
    "#synthetic features to mimic real PE files for training/testing malware detection models.\n",
    "data = []\n",
    "for _ in range(n_samples):\n",
    "    sample = {\n",
    "        'SizeOfHeaders': np.random.randint(200, 1000),\n",
    "        'MajorLinkerVersion': np.random.randint(1, 10),\n",
    "        'MinorLinkerVersion': np.random.randint(0, 10),\n",
    "        'Characteristics': np.random.randint(0, 65535),\n",
    "        'Machine': np.random.choice([332, 34404]),\n",
    "        'num_imported_dlls': np.random.randint(0, 20),\n",
    "        'num_imported_functions': np.random.randint(0, 200),\n",
    "        'num_exported_functions': np.random.randint(0, 50),\n",
    "        'sections': random_sections(np.random.randint(1, n_sections+1)),\n",
    "        'byte_histogram': np.random.randint(0, 1000, size=n_byte_features).tolist()\n",
    "    }\n",
    "    data.append(sample)\n",
    "\n",
    "df = pd.DataFrame(data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0df60914-3d3b-4faa-8a31-ea318ac05cf8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8463d9c2-35e0-4546-800b-ad0d9cc730c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label distribution:\n",
      "label\n",
      "1    4959\n",
      "0      41\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "#To generate binary labels that simulate malware vs. benign classification based on key PE file features.\n",
    "threshold = 4000 # heuristic threshold to divide random data into two classes\n",
    "df['label'] = (\n",
    "    df['SizeOfHeaders'] +\n",
    "    df['byte_histogram'].apply(lambda x: sum(x[:10])) +\n",
    "    df['num_imported_functions']*10\n",
    "    > threshold\n",
    ").astype(int)\n",
    "\n",
    "print(f\"Label distribution:\\n{df['label'].value_counts()}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f14cb4c4-a700-419a-b273-cf8024f679c9",
   "metadata": {},
   "source": [
    "Transforms raw/synthetic PE file metadata into a fixed-length, machine-readable feature vector \n",
    "combining structural features (headers, sections) and statistical features (byte histogram)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7f6f06e7-3706-45b3-83f1-8e89385c50fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature matrix shape: (5000, 266)\n",
      "Labels shape: (5000,)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "#Copy relevant PE header fields (already generated in synthetic data) into clean feature columns for ML\n",
    "def extract_features(df):\n",
    "    df['header_size'] = df['SizeOfHeaders']\n",
    "    df['major_linker'] = df['MajorLinkerVersion']\n",
    "    df['minor_linker'] = df['MinorLinkerVersion']\n",
    "    df['characteristics'] = df['Characteristics']\n",
    "    df['machine'] = df['Machine']\n",
    "    \n",
    "    df['num_imported_functions'] = df['num_imported_functions']\n",
    "    df['num_exported_functions'] = df['num_exported_functions']\n",
    "    \n",
    "    def section_features(sections):\n",
    "        if not isinstance(sections, list) or len(sections) == 0:\n",
    "            return pd.Series([0, 0, 0])\n",
    "        entropies = [s.get('Entropy',0) for s in sections]\n",
    "        vsize = [s.get('VirtualSize',0) for s in sections]\n",
    "        rsize = [s.get('RawSize',0) for s in sections]\n",
    "        return pd.Series([np.mean(entropies), np.sum(vsize), np.sum(rsize)])\n",
    "    \n",
    "    df[['avg_section_entropy','total_virtual_size','total_raw_size']] = df['sections'].apply(section_features)\n",
    "    \n",
    "    bh_df = pd.DataFrame(df['byte_histogram'].tolist(), columns=[f'bh_{i}' for i in range(256)])\n",
    "    \n",
    "    features = pd.concat([\n",
    "        df[['header_size','major_linker','minor_linker','characteristics','machine',\n",
    "            'num_imported_functions','num_exported_functions',\n",
    "            'avg_section_entropy','total_virtual_size','total_raw_size']],\n",
    "        bh_df\n",
    "    ], axis=1).fillna(0)\n",
    "    \n",
    "    return features\n",
    "\n",
    "X = extract_features(df) #Turn raw/synthetic PE file info into numeric features\n",
    "y = df['label'] #target labels (0 = benign, 1 = malware)\n",
    "\n",
    "print(f\"Feature matrix shape: {X.shape}\")  # ~270+ features\n",
    "print(f\"Labels shape: {y.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1065555-17b9-4372-9000-9b5fc20fc93e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "eb1e1e47-9c64-45f7-be04-1ceb2dad8158",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train samples: 4000, Test samples: 1000\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ") # 20% testing and 80% training set\n",
    "\n",
    "print(f\"Train samples: {len(X_train)}, Test samples: {len(X_test)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e352057-2da6-4237-8585-7e626084bab5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "35f8372a-dee6-45f3-97bc-07850ad14871",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 20 rounds\n",
      "[50]\ttrain's auc: 1\tvalid's auc: 0.935862\n",
      "Early stopping, best iteration is:\n",
      "[65]\ttrain's auc: 1\tvalid's auc: 0.956023\n"
     ]
    }
   ],
   "source": [
    "# This block of code is training a LightGBM binary classifier with given hyperparameters,\n",
    "train_data = lgb.Dataset(X_train, label=y_train)\n",
    "valid_data = lgb.Dataset(X_test, label=y_test, reference=train_data)\n",
    "\n",
    "params = {\n",
    "    'objective': 'binary',\n",
    "    'metric': 'auc',\n",
    "    'boosting_type': 'gbdt',\n",
    "    'num_leaves': 31,\n",
    "    'max_depth': 10,\n",
    "    'learning_rate': 0.05,\n",
    "    'feature_fraction': 0.8,\n",
    "    'bagging_fraction': 0.8,\n",
    "    'bagging_freq': 5,\n",
    "    'verbose': -1,\n",
    "    'seed': 42\n",
    "}\n",
    "#using training and validation datasets, running up to 500 boosting rounds but stopping early if validation performance doesnâ€™t improve for 20 rounds\n",
    "model = lgb.train(\n",
    "    params,\n",
    "    train_data,\n",
    "    num_boost_round=500,\n",
    "    valid_sets=[train_data, valid_data],\n",
    "    valid_names=['train','valid'],\n",
    "    callbacks=[early_stopping(stopping_rounds=20), log_evaluation(period=50)]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e5b4665-055a-4a16-98f5-dd40ed7cf2b5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "497b2477-edee-42e7-937a-fbcbbc01b52c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9920\n",
      "ROC AUC: 0.9560\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         8\n",
      "           1       0.99      1.00      1.00       992\n",
      "\n",
      "    accuracy                           0.99      1000\n",
      "   macro avg       0.50      0.50      0.50      1000\n",
      "weighted avg       0.98      0.99      0.99      1000\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\TsheringTobzang\\AppData\\Local\\miniconda3\\envs\\mlhack\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1706: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "C:\\Users\\TsheringTobzang\\AppData\\Local\\miniconda3\\envs\\mlhack\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1706: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "C:\\Users\\TsheringTobzang\\AppData\\Local\\miniconda3\\envs\\mlhack\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1706: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n"
     ]
    }
   ],
   "source": [
    "y_pred_prob = model.predict(X_test, num_iteration=model.best_iteration)\n",
    "y_pred = (y_pred_prob >= 0.5).astype(int)\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "roc_auc = roc_auc_score(y_test, y_pred_prob)\n",
    "\n",
    "print(f\"Accuracy: {accuracy:.4f}\")\n",
    "print(f\"ROC AUC: {roc_auc:.4f}\")\n",
    "print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f985220a-9cab-4b25-854c-938da36e7d23",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
