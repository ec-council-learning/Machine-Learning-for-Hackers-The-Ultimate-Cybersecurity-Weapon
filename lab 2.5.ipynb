{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e4df9e99-1125-40b1-8d65-13cfeb131c47",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "from torch.utils.data import DataLoader, TensorDataset\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dd96ce0-300d-47f1-81dc-e11d1ef45f80",
   "metadata": {},
   "source": [
    "MalConv Model MalConv (Malware Convolutional Neural Network) is a deep learning model for malware detection that takes raw bytes of a binary file (like a Windows PE file) as input — without requiring manual feature extraction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cdfc0a6d-2142-4bd1-a044-775d074e0c28",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MalConv(nn.Module): #Defines a PyTorch neural network class setting up a model that can learn patterns directly from raw bytes.\n",
    "    def __init__(self, n_emb=257, emb_dim=8):\n",
    "        super(MalConv, self).__init__()                               #initializes the base nn.Module class so we can use PyTorch functionalities.\n",
    "        self.embedding = nn.Embedding(n_emb, emb_dim, padding_idx=0) #Converts each byte into a trainable vector of length 8 \n",
    "        self.conv1 = nn.Conv1d(emb_dim, 128, kernel_size=500, stride=500) #1D convolution slides a filter over sequences of embeddings\n",
    "        self.relu = nn.ReLU()                                         #Applies ReLU to introduce non-linearity Negative values become zero\n",
    "        self.dropout = nn.Dropout(0.5)                                # Randomly sets 50% of inputs to zero during training-prevents overfitting\n",
    "        self.fc = nn.Linear(128, 1)                                   # Maps the 128 features from the convolution to one scalar output/logit\n",
    "        self.sigmoid = nn.Sigmoid()                                    #Converts the scalar output into a probability between 0 and 1\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.embedding(x).permute(0, 2, 1)  # batch x emb_dim x seq_len\n",
    "        x = self.conv1(x) #1D convolution scans 500-byte chunks with 128 filters\n",
    "        x = self.relu(x)\n",
    "        x = torch.max(x, 2)[0]  # global max pooling For each filter, pick the maximum activation across all chunks\n",
    "        x = self.dropout(x) \n",
    "        x = self.fc(x) #Combines all 128 strongest clues into one scalar score.\n",
    "        return self.sigmoid(x)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ab74c63-4954-4fce-99db-976502ccaa65",
   "metadata": {},
   "source": [
    "Create Synthetic Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e3228e8c-d8bf-4a38-b477-f8e97d48d2da",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "torch.manual_seed(42)\n",
    "\n",
    "num_samples = 200\n",
    "seq_len = 2000  # short for demo\n",
    "\n",
    "# Malware: higher byte values, Benign: lower byte values\n",
    "malware_data = np.random.randint(100, 256, (num_samples//2, seq_len))\n",
    "benign_data = np.random.randint(1, 100, (num_samples//2, seq_len))\n",
    "\n",
    "\n",
    "X = np.vstack((malware_data, benign_data)) #Combine Malware and Benign\n",
    "y = np.hstack((np.ones(num_samples//2), np.zeros(num_samples//2))) #Assign labels: 1 = malware, 0 = benign.\n",
    "\n",
    "#Convert numpy arrays to tensors for PyTorch\n",
    "X_tensor = torch.tensor(X, dtype=torch.long)\n",
    "y_tensor = torch.tensor(y, dtype=torch.float32).unsqueeze(1)\n",
    "\n",
    "#Create Dataset\n",
    "dataset = TensorDataset(X_tensor, y_tensor)\n",
    "train_loader = DataLoader(dataset, batch_size=16, shuffle=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f16a352b-00da-4fc4-827d-a35ee572ac92",
   "metadata": {},
   "source": [
    "Train the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5196b991-434b-4b60-b76c-2d57e2e236f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/5] - Loss: 0.3105\n",
      "Epoch [2/5] - Loss: 0.0083\n",
      "Epoch [3/5] - Loss: 0.0013\n",
      "Epoch [4/5] - Loss: 0.0007\n",
      "Epoch [5/5] - Loss: 0.0008\n"
     ]
    }
   ],
   "source": [
    "\n",
    "model = MalConv() #Initializes your MalConv network with all layers\n",
    "criterion = nn.BCELoss() #Binary Cross Entropy (BCE) loss compares the predicted probability vs the true label\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001) #Adam optimizer updates the model parameters to reduce the loss.\n",
    "\n",
    "epochs = 5\n",
    "for epoch in range(epochs):\n",
    "    total_loss = 0\n",
    "    for inputs, labels in train_loader:      #loop over the training dataset in batches\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)    #compute the loss (error) between predictions and true labels.\n",
    "        loss.backward()                      #computes the gradients of the loss with respect to all model parameters.\n",
    "        optimizer.step()                     #The optimizer updates the model’s weights using the gradients computed in loss.backward()\n",
    "        total_loss += loss.item()\n",
    "    print(f\"Epoch [{epoch+1}/{epochs}] - Loss: {total_loss/len(train_loader):.4f}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31d53921-dd16-43c8-8ab6-a3ebbcd0021a",
   "metadata": {},
   "source": [
    "Pick a Malware Sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b0c9f25e-de7b-48c8-b073-280134452cc9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True label: 1.0\n",
      "Original score: 0.9999697208404541\n"
     ]
    }
   ],
   "source": [
    "#Feed a single sample through the model to check its true label and predicted score.\n",
    "sample_idx = 0  # first malware sample\n",
    "sample = X_tensor[sample_idx].unsqueeze(0)  # shape (1, seq_len)\n",
    "label = y_tensor[sample_idx]\n",
    "\n",
    "print(\"True label:\", label.item())\n",
    "print(\"Original score:\", model(sample).item())\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48888a8d-d1c7-43c5-af9b-db7510689f2a",
   "metadata": {},
   "source": [
    "FGSM Adversarial Attack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "9036a33b-52fa-4fc6-b490-71d2d1022266",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get embedding weights for gradient computation\n",
    "sample_input = sample.clone().detach()                                \n",
    "embedded = model.embedding(sample_input).detach().requires_grad_(True) # coverting raw bytes to dense embeding vectos\n",
    "\n",
    "# Forward pass manually through remaining layers\n",
    "x = embedded.permute(0, 2, 1)    #Reorder tensor to match layer’s expected input\n",
    "x = model.conv1(x)\n",
    "x = model.relu(x)\n",
    "x = torch.max(x, 2)[0]      #Global max pooling converts variable-length convolution outputs into a fixed-size vector\n",
    "x = model.dropout(x)\n",
    "x = model.fc(x)\n",
    "output = model.sigmoid(x)   # activation fuction used to converts logits to probablities(0,1)\n",
    "\n",
    "# Compute loss targeting benign (0.0)\n",
    "loss = criterion(output, torch.tensor([[0.0]]))\n",
    "loss.backward()\n",
    "\n",
    "# FGSM on embeddings\n",
    "epsilon = 3.0\n",
    "perturbed_embedded = embedded - epsilon * embedded.grad.sign()\n",
    "\n",
    "# Map perturbed embeddings back to nearest byte index to save it as file as adversarial prediction require new perturbed file to predict\n",
    "embedding_weights = model.embedding.weight.detach()\n",
    "byte_indices = torch.cdist(\n",
    "    perturbed_embedded.view(-1, embedded.shape[2]),\n",
    "    embedding_weights\n",
    ").argmin(dim=1)\n",
    "\n",
    "# Reshape back to original shape\n",
    "adv_sample = byte_indices.view(sample_input.shape).clamp(1, 255)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cf7136d-a593-47e9-bde5-e7db419f7864",
   "metadata": {},
   "source": [
    "Compare Scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "4078f25b-fe8b-496c-bace-c4b7e24133db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original detection score: 0.9998 (malware)\n",
      "Adversarial detection score: 0.0000 (closer to benign means evasion)\n"
     ]
    }
   ],
   "source": [
    "orig_score = model(sample).item()\n",
    "adv_score = model(adv_sample).item()\n",
    "\n",
    "print(f\"Original detection score: {orig_score:.4f} (malware)\")\n",
    "print(f\"Adversarial detection score: {adv_score:.4f} (closer to benign means evasion)\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f6f62fb-1ee7-4df3-a39f-312dd93ba243",
   "metadata": {},
   "source": [
    "Visual Difference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a31614d9-2271-457f-9cea-fbdf83fb982b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bytes changed: 1969 out of 2000\n"
     ]
    }
   ],
   "source": [
    "diff_bytes = (adv_sample != sample).sum().item()\n",
    "print(f\"Bytes changed: {diff_bytes} out of {seq_len}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07f4d0e3-ca9a-4624-a063-41e5badeb960",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
